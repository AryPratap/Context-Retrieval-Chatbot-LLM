{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeLAJpd03qPA",
        "outputId": "8bcf010e-7095-462a-c4fb-8e195f8e9d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Kykl0C4CQr"
      },
      "outputs": [],
      "source": [
        "%pip install \"pdf2image\" \"pytesseract\" \"tiktoken\" \"langchain\" \"sentence-transformers\" \"unstructured\" \n",
        "%pip install chromadb==0.3.29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vLHPLMrY4IFD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from chromadb.config import Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dur2LLlr4JuE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import glob\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "from multiprocessing import Pool\n",
        "from tqdm import tqdm\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import (\n",
        "    PDFMinerLoader,\n",
        ")\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.text_splitter import TokenTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DqD1NFLd4MwN"
      },
      "outputs": [],
      "source": [
        "# Define the folder for storing database\n",
        "persist_directory = 'AllMini_Chroma_Tik_400' # add the name of the folder where you want to store vectorDB\n",
        "\n",
        "# Define the Chroma settings\n",
        "CHROMA_SETTINGS = Settings(\n",
        "        chroma_db_impl='duckdb+parquet',\n",
        "        persist_directory=persist_directory,\n",
        "        anonymized_telemetry=False\n",
        ")\n",
        "# path to the source documents\n",
        "source_directory= \"/content/drive/MyDrive/daiict_webCrawl self data with chromadb private gpt/web crawl_DAIICT/docs/daiict.ac.in\"\n",
        "# define text chunk size and overlap\n",
        "chunk_size = 400\n",
        "chunk_overlap = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b1xPelJS4RcY"
      },
      "outputs": [],
      "source": [
        "# load single document\n",
        "def load_single_document(file_path: str) -> List[Document]:\n",
        "  \"\"\"\n",
        "  Function responsible for loading pdf and text files and data cleaning.\n",
        "  \"\"\"\n",
        "  # define data loader as per file type\n",
        "  if file_path[-3:]==\"pdf\":\n",
        "    loader = PDFMinerLoader(file_path)\n",
        "  else:\n",
        "    loader = UnstructuredFileLoader(file_path)\n",
        "\n",
        "  # load data from file\n",
        "  result = loader.load()\n",
        "  page_content = result[0].page_content\n",
        "  # Remove extra breaklines from the text.\n",
        "  page_content = page_content.replace('\\n',' ').replace('\\\\n',' ')\n",
        "  # Remove continous extraspaces from the text\n",
        "  page_content = re.sub(r\"\\s+\", \" \", page_content)\n",
        "  result[0].page_content = page_content\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U3GHoeOI4Wr8"
      },
      "outputs": [],
      "source": [
        "def load_documents(source_dir: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Loads all documents from the source documents directory.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    all_file_paths = []\n",
        "    # text file paths\n",
        "    txt_files = glob.glob(os.path.join(source_dir, '*.txt'))\n",
        "    # pdf files paths\n",
        "    pdf_files = glob.glob(os.path.join(source_dir, '*.pdf'))\n",
        "    all_file_paths.extend(txt_files)\n",
        "    all_file_paths.extend(pdf_files)\n",
        "\n",
        "    # remove files .zip type\n",
        "    all_file_paths = [file for file in all_file_paths if not file.endswith('.zip')]\n",
        "    for file in all_file_paths:\n",
        "      # remove xls files in txt format\n",
        "      if(file[-7:]!='xls.txt'):\n",
        "        doc = load_single_document(file)\n",
        "        results.extend(doc)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EhqXPnIt4ZRl"
      },
      "outputs": [],
      "source": [
        "def process_documents() -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load documents and split in chunks\n",
        "    \"\"\"\n",
        "    print(f\"Loading documents from {source_directory}\")\n",
        "    documents = load_documents(source_directory)\n",
        "    if not documents:\n",
        "        print(\"No new documents to load\")\n",
        "        exit(0)\n",
        "    print(f\"Loaded {len(documents)} new documents from {source_directory}\")\n",
        "    # define text splitter\n",
        "    text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    print(f\"Split into {len(texts)} chunks of text (max. {chunk_size} tokens each)\")\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dFQ1XBHM4hlN"
      },
      "outputs": [],
      "source": [
        "def does_vectorstore_exist(persist_directory: str) -> bool:\n",
        "    \"\"\"\n",
        "    Checks if vectorstore exists\n",
        "    \"\"\"\n",
        "    if os.path.exists(os.path.join(persist_directory, 'index')):\n",
        "        if os.path.exists(os.path.join(persist_directory, 'chroma-collections.parquet')) and os.path.exists(os.path.join(persist_directory, 'chroma-embeddings.parquet')):\n",
        "            list_index_files = glob.glob(os.path.join(persist_directory, 'index/*.bin'))\n",
        "            list_index_files += glob.glob(os.path.join(persist_directory, 'index/*.pkl'))\n",
        "            # At least 3 documents are needed in a working vectorstore\n",
        "            if len(list_index_files) > 3:\n",
        "                return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M6x0KXrL4jI4"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Run this for creating vector database\n",
        "\n",
        "    \"\"\"\n",
        "    # load embeddings model\n",
        "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    if does_vectorstore_exist(persist_directory):\n",
        "        # Update and store locally vectorstore\n",
        "        print(f\"Appending to existing vectorstore at {persist_directory}\")\n",
        "        db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n",
        "        collection = db.get()\n",
        "        texts = persist_directory([metadata['source'] for metadata in collection['metadatas']])\n",
        "        print(f\"Creating embeddings. May take some minutes...\")\n",
        "        db.add_documents(texts)\n",
        "    else:\n",
        "        # Create and store locally vectorstore\n",
        "        print(\"Creating new vectorstore\")\n",
        "        texts = process_documents()\n",
        "        print(f\"Creating embeddings. May take some minutes...\")\n",
        "        db = Chroma.from_documents(texts, embeddings, persist_directory=persist_directory, client_settings=CHROMA_SETTINGS)\n",
        "    db.persist()\n",
        "    db = None\n",
        "\n",
        "    print(f\"Ingestion complete! You can now run query the vectorDB for context retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfl0AWOlq8VY",
        "outputId": "57356135-f650-4bfb-87b3-b9441324fda4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/final VectorDBs/Daiict\n"
          ]
        }
      ],
      "source": [
        "#Enter path to store the vectorDB\n",
        "%cd /content/drive/MyDrive/final VectorDBs/Daiict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SPLcrq84kka"
      },
      "outputs": [],
      "source": [
        "# Only run when creating vectorStore\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6ylLgTnubVL"
      },
      "source": [
        "#Context retrieval on vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-XhkbEe9Wt2"
      },
      "outputs": [],
      "source": [
        "# load embeddings model\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t6DuDxAHoxA"
      },
      "outputs": [],
      "source": [
        "# define vectorDB directory and ChromaDB settings\n",
        "persist_directory = \"AllMpnet_Chroma_Tik_500\"\n",
        "CHROMA_SETTINGS = Settings(\n",
        "        chroma_db_impl='duckdb+parquet',\n",
        "        persist_directory=persist_directory,\n",
        "        anonymized_telemetry=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x8XgRbSHtQT",
        "outputId": "28d86169-539b-4c80-993c-bdcb96370fc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: AllMpnet_Chroma_Tik_500\n"
          ]
        }
      ],
      "source": [
        "# vectorDB instance\n",
        "db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHmleUKlHvE7"
      },
      "outputs": [],
      "source": [
        "# query the vectorDB\n",
        "query = \"Name professors in cse department\"\n",
        "\n",
        "# use vectorDB as retriever with top k retrieved context\n",
        "retriever = db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 2})\n",
        "retriever.get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgb8GdUmHxvQ"
      },
      "outputs": [],
      "source": [
        "# Retrieval context with similarity score\n",
        "query = \"Who are the Alumni Association Members?\"\n",
        "docs = db.similarity_search_with_score(query)\n",
        "docs[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
